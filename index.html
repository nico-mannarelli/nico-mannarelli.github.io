<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>d09603b25479481d9035a1d839566d29</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell markdown" id="9QAHoy_WPXzq">
<h1 id="earthquake-activity-analysis">"Earthquake Activity
Analysis"</h1>
<p>"Summer 2025 Data Science Project"</p>
<p>Names:Nico Mannarelli, Hamelmal Idosa, Joseph Taylor, Melodie
Galamo</p>
<hr />
<h1 id="contributions">"Contributions"</h1>
<ul>
<li><p>A: Project Idea<br />
Nico proposed using USGS earthquake data to explore depth and magnitude
relationships globally.</p></li>
<li><p>B: Dataset Curation and Preprocessing Hamelmal handled
downloading the dataset, filtering only valid <code>earthquake</code>
types, and parsing datetime columns.</p></li>
<li><p>C: Data Exploration and Summary Statistics<br />
Joseph performed hypothesis testing and generated visualizations for
magnitude comparisons and categorical features.</p></li>
<li><p>D: ML Algorithm Design/Development Melodie developed regression
models including linear regression and random forest for predicting
magnitude.</p></li>
<li><p>E: ML Algorithm Training and Test Data Analysis Joseph and
Melodie handled model evaluation with metrics like RMSE and R² using
scikit-learn.</p></li>
<li><p>F: Visualization, Result Analysis, Conclusion<br />
Hamelmal created summary plots and visualizations to compare actual vs.
predicted magnitude and explain model results.</p></li>
<li><p>G: Final Tutorial Report Creation<br />
All members contributed to writing and formatting the notebook as a
GitHub Pages-ready tutorial.</p></li>
<li><p>H: Additional<br />
Hamelmal coordinated the team’s GitHub setup and HTML export process for
project submission.</p></li>
</ul>
</div>
<section id="introduction" class="cell markdown" id="_0XUrh1QHbsK">
<h1><strong>Introduction</strong></h1>
<p>The main purpose of this project is to walk through the full pipeline
of data science using real-world, high-impact data. To do this, we chose
to focus on earthquakes, a natural phenomenon that continues to have
devastating effects across the globe. Earthquakes are unpredictable,
destructive, and can drastically alter both natural landscapes and human
societies in a matter of seconds. By using recent and historical seismic
data, we aim to understand earthquake behavior more clearly and explore
whether data science techniques can help uncover meaningful
insights.</p>
<p>We are using a dataset provided by the United States Geological
Survey (USGS), which offers detailed records on recent global
earthquakes. These records include attributes such as the earthquake's
magnitude, depth, location, time, and type. With this dataset, we seek
to the key question:</p>
<ul>
<li>Can we use features like location and depth to predict earthquake
strength or classify seismic events?</li>
</ul>
<p><strong>Why is this important?</strong></p>
<p>Earthquakes cause thousands of deaths, injuries, and billions of
dollars in property damage every year. As climate patterns and tectonic
pressures shift over time, it becomes increasingly important to monitor
seismic activity and learn from historical patterns. By using data
science to analyze this information, we can support efforts in disaster
preparedness, risk mitigation, and public safety. For example,
identifying regional trends or statistically significant depth-magnitude
relationships can help prioritize infrastructure reinforcement and
emergency planning in earthquake-prone areas.</p>
</section>
<section id="data-collection" class="cell markdown" id="43AhoPbEHo0D">
<h1><strong>Data Collection</strong></h1>
<p>At this stage of the Data Science lifecycle, we focused on finding a
dataset relevant to our topic: earthquake activity around the world.
Just like any scientific study, it was important to ensure that the data
we used came from a credible and authoritative source. Fortunately, we
were able to find a detailed and up-to-date dataset through the United
States Geological Survey (USGS) website.</p>
<p>The USGS Earthquake Catalog provides extensive data on seismic
events, including the time, magnitude, depth, and geographic location of
each earthquake, along with additional metadata. We downloaded the
dataset in .csv format, which contained earthquake data from the past
month, and loaded it directly into our project directory for
analysis.</p>
<p>However, we knew that just the raw event listings wouldn't be enough,
we needed to refine and clean the data before we could begin analysis.
For example, we filtered out non-earthquake events (explosions,quarry
blasts...), handled missing values in important fields like magnitude
and depth, and converted timestamps into a usable datetime format.</p>
<p>This initial data collection and preprocessing step laid the
foundation for our subsequent exploratory analysis and hypothesis
testing.</p>
</section>
<div class="cell code" data-execution_count="78"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="B2KoeNVyAA5H" data-outputId="ce0d3005-43d6-4ee2-dc23-9e1b0fbb92d8">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.graphics.mosaicplot <span class="im">import</span> mosaic</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.stats.multicomp <span class="im">import</span> pairwise_tukeyhsd</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, GridSearchCV</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score, mean_squared_error</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_and_clean(path):</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co">    Load the CSV, filter for earthquakes, drop missing values,</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co">    extract region, and cast to categories.</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> (</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        pd.read_csv(path, parse_dates<span class="op">=</span>[<span class="st">&#39;time&#39;</span>])</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>          .query(<span class="st">&quot;type == &#39;earthquake&#39;&quot;</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>          .dropna(subset<span class="op">=</span>[<span class="st">&#39;mag&#39;</span>, <span class="st">&#39;depth&#39;</span>, <span class="st">&#39;place&#39;</span>])</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract region from &#39;place&#39;</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;region&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;place&#39;</span>].<span class="bu">str</span>.extract(<span class="vs">r&#39;,\s*(.*)&#39;</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Drop any rows without a region</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df[df[<span class="st">&#39;region&#39;</span>].notna()]</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Cast region to categorical</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;region&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;region&#39;</span>].astype(<span class="st">&#39;category&#39;</span>)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df.reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and clean</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> load_and_clean(<span class="st">&quot;/content/sample_data/all_month.csv&quot;</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.columns)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Index([&#39;time&#39;, &#39;latitude&#39;, &#39;longitude&#39;, &#39;depth&#39;, &#39;mag&#39;, &#39;magType&#39;, &#39;nst&#39;,
       &#39;gap&#39;, &#39;dmin&#39;, &#39;rms&#39;, &#39;net&#39;, &#39;id&#39;, &#39;updated&#39;, &#39;place&#39;, &#39;type&#39;,
       &#39;horizontalError&#39;, &#39;depthError&#39;, &#39;magError&#39;, &#39;magNst&#39;, &#39;status&#39;,
       &#39;locationSource&#39;, &#39;magSource&#39;, &#39;region&#39;],
      dtype=&#39;object&#39;)
</code></pre>
</div>
</div>
<section id="exploratory-data-analysis" class="cell markdown"
id="Uc84us3vP9H_">
<h1><strong>Exploratory Data Analysis</strong></h1>
<p>Let's create some hypothesis to reveal relationships in the data,
this will help us understnad which features are related so that we can
create an efficient model.</p>
</section>
<div class="cell markdown" id="QBdEFKNUqbbu">
<p>##Test 1:</p>
<p>Null Hypotheis: The average magnitude of earthquakes ocurring at
&lt;= 70km deep is the same as the average magnitude of earthquakes
occuring at &gt; 70km deep</p>
<p>Alternative Hypothesis: The average magnitude of earthquakes &lt;= 70
km deep is different than the average magnitude of earthquakes &gt; 70km
deep</p>
</div>
<div class="cell code" data-execution_count="79"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="J_s43eaqyZEq" data-outputId="cbaf5961-4970-46f9-9995-a60d429775e2">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">#load dataset</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&quot;/content/sample_data/all_month.csv&quot;</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Original dataframe: &quot;</span>, df.shape)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co">#filter  to get correct depths</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;depth_cat&#39;</span>] <span class="op">=</span> np.where(df[<span class="st">&#39;depth&#39;</span>] <span class="op">&lt;=</span> <span class="dv">70</span>, <span class="st">&#39;Shallow (&lt;=70km)&#39;</span>, <span class="st">&#39;Deep (&gt;70km)&#39;</span>)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co">#convert time</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;time&#39;</span>] <span class="op">=</span> pd.to_datetime(df[<span class="st">&#39;time&#39;</span>])</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[df[<span class="st">&#39;type&#39;</span>] <span class="op">==</span> <span class="st">&#39;earthquake&#39;</span>]</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co">#drop rows with null values</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.dropna(subset<span class="op">=</span>[<span class="st">&#39;mag&#39;</span>, <span class="st">&#39;depth&#39;</span>])</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>shallow <span class="op">=</span>  df[df[<span class="st">&#39;depth_cat&#39;</span>] <span class="op">==</span> <span class="st">&#39;Shallow (&lt;=70km)&#39;</span>][<span class="st">&#39;mag&#39;</span>]<span class="co">#df[df[&#39;depth&#39;] &lt;= 70][&#39;mag&#39;].copy()</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co">#print(shallow)</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>deep <span class="op">=</span> df[df[<span class="st">&#39;depth_cat&#39;</span>] <span class="op">==</span> <span class="st">&#39;Deep (&gt;70km)&#39;</span>][<span class="st">&#39;mag&#39;</span>]<span class="co">#df[df[&#39;depth&#39;] &gt;  70][&#39;mag&#39;].copy()</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="co">#get means of data</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>mean_shal, mean_dp <span class="op">=</span> shallow.mean(), deep.mean()</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>sd_shal, sd_dp <span class="op">=</span> shallow.std(), deep.std()</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Dataframe with no earthquake values: &quot;</span>, df.shape)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;number_of_shallow =&quot;</span>, <span class="bu">len</span>(shallow), <span class="st">&quot;number_of_deep =&quot;</span>, <span class="bu">len</span>(deep))</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Shallow mean: = </span><span class="sc">{</span>mean_shal<span class="sc">:.2f}</span><span class="ss">, standard deviation = </span><span class="sc">{</span>sd_shal<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Deep mean:    = </span><span class="sc">{</span>mean_dp<span class="sc">:.2f}</span><span class="ss">, standard deviation = </span><span class="sc">{</span>sd_dp<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a><span class="co">#https://www.statology.org/levenes-test-python/</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>_, levene_pvalue <span class="op">=</span> stats.levene(shallow, deep)</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Levene’s p‐value =&quot;</span>, levene_pvalue)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>equal_var <span class="op">=</span> (levene_pvalue <span class="op">&gt;</span> <span class="fl">0.05</span>)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>t_stat, p_val <span class="op">=</span> stats.ttest_ind(shallow, deep, equal_var<span class="op">=</span>equal_var)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;t = </span><span class="sc">{</span>t_stat<span class="sc">:.3f}</span><span class="ss">, p = </span><span class="sc">{</span>p_val<span class="sc">:.3e}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Original dataframe:  (9787, 22)
Dataframe with no earthquake values:  (9586, 23)
number_of_shallow = 8798 number_of_deep = 788
Shallow mean: = 1.44, standard deviation = 1.16
Deep mean:    = 2.83, standard deviation = 1.30
Levene’s p‐value = 9.043861525139562e-20
t = -29.059, p = 1.226e-131
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="80"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:410}"
id="uob67PEGr3Y7" data-outputId="6593e2ae-dc21-46f8-99e3-6e7bffd83696">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">4</span>))</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>plt.hist(shallow, bins<span class="op">=</span><span class="dv">30</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, density<span class="op">=</span><span class="va">True</span>, label<span class="op">=</span><span class="st">&quot;Shallow&quot;</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>plt.hist(deep,    bins<span class="op">=</span><span class="dv">30</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, density<span class="op">=</span><span class="va">True</span>, label<span class="op">=</span><span class="st">&quot;Deep&quot;</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Magnitude&quot;</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Density&quot;</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Magnitude Distributions by Depth&quot;</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_f94581669a5f4ed79b9d0a92767380fb/d556392cbd3fd97baedad3e41e9c6cbeffe691d3.png" /></p>
</div>
</div>
<div class="cell markdown" id="kPbFYiKRQYaK">
<p>Conclusion: From our graph and significantly low p-value we can
conclude that our alternative hypothesis to be correct that earthquakes
occuring at deeper depths yield a significantly higher average magnitude
compared to shallower depths.</p>
<p>Some characteristics is the overrepresentation of shallow
earthquakes, we see there is significantly more data on shallow
earthquakes compared to deeper ones. (This could potentially be better
balanced if we changed the threshhold defining a deep vs shallow
earthquake).</p>
</div>
<div class="cell markdown" id="d-eXpZGdu0yX">
<p>##Test 2 : Determining whether the type of seismic event is
independent of the region where it occurred using a chi-squared test of
independence.</p>
<p>Null Hypothesis : There is no association between the region and the
type of seismic event. The distribution of event types is the same
across all regions.</p>
<p>Alternate Hypothesis : There is an association between the region and
the type of seismic event. The distribution of event types differs
between regions.</p>
</div>
<div class="cell code" data-execution_count="81"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:678}"
id="gfj0Tj_bu3or" data-outputId="5b4da8a8-3ad0-4f19-e2ad-2599ff994963">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> chi2_contingency</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">#load dataset</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&#39;/content/sample_data/all_month.csv&#39;</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># get regions and simplify</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;region&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;place&#39;</span>].<span class="bu">str</span>.extract(<span class="vs">r&#39;,\s*(.*)&#39;</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># grab only top 10 regions</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>top_regions <span class="op">=</span> df[<span class="st">&#39;region&#39;</span>].value_counts().head(<span class="dv">10</span>).index</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>filtered_df <span class="op">=</span> df[df[<span class="st">&#39;region&#39;</span>].isin(top_regions)]</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>contingency_table <span class="op">=</span> pd.crosstab(filtered_df[<span class="st">&#39;region&#39;</span>], filtered_df[<span class="st">&#39;type&#39;</span>])</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># create contingency table</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>contingency_table <span class="op">=</span> pd.crosstab(filtered_df[<span class="st">&#39;region&#39;</span>], filtered_df[<span class="st">&#39;type&#39;</span>])</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co">#run test</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>chi2, p, dof, expected <span class="op">=</span> chi2_contingency(contingency_table)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="co">#print results</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Chi-squared test results:&quot;</span>)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;p-value:&quot;</span>, p)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Chi-squared statistic:&quot;</span>, chi2)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Degrees of freedom:&quot;</span>, dof)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="co">#plot resulsts</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>contingency_table.plot(kind<span class="op">=</span><span class="st">&quot;bar&quot;</span>, stacked<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>ax)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Distribution of Seismic Event Types by Region (Top 10 Regions)&quot;</span>)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Region&quot;</span>)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Number of Events&quot;</span>)</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">&#39;right&#39;</span>)</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Chi-squared test results:
p-value: 3.583461389400531e-170
Chi-squared statistic: 921.9238324760231
Degrees of freedom: 36
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_f94581669a5f4ed79b9d0a92767380fb/3ed4ed53149fc8c62c038ff204cb0427e0346605.png" /></p>
</div>
</div>
<div class="cell markdown" id="7q0a27qv4OTn">
<p>Conclusion : From the graph and the low p-value, we reject the null
can see that there is a statistically significant association between
the region and the type of seismic event. This suggests that different
regions experience different types of seismic events (earthquakes,
quarry blasts, explosions) with varying frequencies, and the
distribution of event types is not uniform across regions.</p>
</div>
<div class="cell markdown" id="usgYPiPrbMgw">
<p>##Test 3: Null Hypothesis: There is no difference in average
earthquake magnitudes between regions.</p>
<p>Alternative Hypothesis: At least one region has a significantly
different average magnitude.</p>
</div>
<div class="cell code" data-execution_count="82"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:868}"
id="E0Qqz5IxZhtO" data-outputId="b8f3558f-f5aa-4028-d4ac-141d99ec0491">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&#39;/content/sample_data/all_month.csv&#39;</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.dropna(subset<span class="op">=</span>[<span class="st">&#39;mag&#39;</span>, <span class="st">&#39;latitude&#39;</span>, <span class="st">&#39;longitude&#39;</span>, <span class="st">&#39;place&#39;</span>])</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">#clean location column</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;region&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;place&#39;</span>].<span class="bu">str</span>.extract(<span class="vs">r&#39;,\s*(.*)&#39;</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co">#Top 5 regions</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>top_regions <span class="op">=</span> df[<span class="st">&#39;region&#39;</span>].value_counts().nlargest(<span class="dv">5</span>).index</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>df_top <span class="op">=</span> df[df[<span class="st">&#39;region&#39;</span>].isin(top_regions)]</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co"># ANOVA test</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>groups <span class="op">=</span> [group[<span class="st">&#39;mag&#39;</span>].values <span class="cf">for</span> name, group <span class="kw">in</span> df_top.groupby(<span class="st">&#39;region&#39;</span>)]</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>f_stat, p_val <span class="op">=</span> stats.f_oneway(<span class="op">*</span>groups)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;ANOVA F-statistic:&quot;</span>, f_stat)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;p-value:&quot;</span>, p_val)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>sns.boxplot(x<span class="op">=</span><span class="st">&#39;region&#39;</span>, y<span class="op">=</span><span class="st">&#39;mag&#39;</span>, data<span class="op">=</span>df_top)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Earthquake Magnitude by Top 5 Regions&#39;</span>)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Region&#39;</span>)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Magnitude&#39;</span>)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Tukey&#39;s HSD post-hoc</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>tukey <span class="op">=</span> pairwise_tukeyhsd(endog<span class="op">=</span>df_top[<span class="st">&#39;mag&#39;</span>],</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>                          groups<span class="op">=</span>df_top[<span class="st">&#39;region&#39;</span>],</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>                          alpha<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tukey)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>ANOVA F-statistic: 237.40630262323063
p-value: 7.249115801343226e-192
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_f94581669a5f4ed79b9d0a92767380fb/1ec6b5936cb16b56a26de42ba79090f60f0b213c.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>    Multiple Comparison of Means - Tukey HSD, FWER=0.05     
============================================================
  group1     group2   meandiff p-adj   lower   upper  reject
------------------------------------------------------------
    Alaska         CA   -0.382    0.0 -0.4378 -0.3261   True
    Alaska     Nevada  -0.5245    0.0  -0.652  -0.397   True
    Alaska New Mexico    0.522    0.0  0.4144  0.6297   True
    Alaska      Texas   0.2407    0.0  0.1406  0.3408   True
        CA     Nevada  -0.1425 0.0169 -0.2682 -0.0169   True
        CA New Mexico    0.904    0.0  0.7986  1.0094   True
        CA      Texas   0.6227    0.0   0.525  0.7204   True
    Nevada New Mexico   1.0465    0.0  0.8908  1.2023   True
    Nevada      Texas   0.7652    0.0  0.6146  0.9158   True
New Mexico      Texas  -0.2814    0.0 -0.4156 -0.1471   True
------------------------------------------------------------
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="82" id="XI8tcOdLfBhG">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
<div class="cell markdown" id="HyzDgSdBmUfu">
<p>The ANOVA test resulted in an F-statistic of 234.22 and a p-value of
approximately 1.47 × 10⁻¹⁸⁹, which is far below any conventional
significance level (e.g., 0.05). This provides strong evidence against
the null hypothesis, indicating that there are statistically significant
differences in average earthquake magnitudes across the top 5 regions.
In other words, earthquake magnitudes vary by region, and region plays
an important role in the distribution of seismic intensity.</p>
</div>
<div class="cell markdown" id="LTc81YbReuEq">
<p><strong>Overall</strong></p>
<ol>
<li><p>T-Test: Compared magnitudes of shallow (&lt; 70km) and deep (≥
70km) earthquakes. Result: Significant difference found.</p></li>
<li><p>Correlation Analysis: Found a statistically significant positive
correlation between earthquake depth and magnitude. Each test was paired
with a labeled plot and interpreted in context.</p></li>
</ol>
</div>
<section id="primary-analysis" class="cell markdown" id="FWN8uBieYJjO">
<h1>Primary Analysis</h1>
</section>
<div class="cell markdown" id="uVjvs4EwaG-x">
<p>In this step we plan to build a predictive model that helps us go
beyond analysis and begin to forecast or explain values based on
relationships in the data. For this project, we chose to use linear
regression, a widely used and interpretable machine learning method.</p>
<p>Our goal was to see whether we could predict the magnitude of an
earthquake using features such as depth, latitude, and longitude. Linear
regression allows us to model this as a continuous outcome, giving us a
sense of how different factors contribute to the severity of an
earthquake.</p>
<p>For the first approach lets use a linear regression model ...</p>
</div>
<div class="cell markdown" id="2qaMHOtQ4kFf">
<p><strong>imports</strong></p>
</div>
<div class="cell code" data-execution_count="83" id="zyOw3YOx4rOd">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score, mean_squared_error</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code></pre></div>
</div>
<div class="cell markdown" id="eZyzFXr2d5F8">
<p>First, lets reload the data and clean it to isolate the relevant
features</p>
</div>
<div class="cell code" data-execution_count="84"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="gbPV_B1mYs6z" data-outputId="62957c4b-c06d-4e7c-e181-18830750cbcb">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">#load dataset</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>earthquake_df <span class="op">=</span> pd.read_csv(<span class="st">&quot;/content/sample_data/all_month.csv&quot;</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co">#get relevant features</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>columns_of_interest <span class="op">=</span> [<span class="st">&#39;mag&#39;</span>, <span class="st">&#39;depth&#39;</span>, <span class="st">&#39;latitude&#39;</span>, <span class="st">&#39;longitude&#39;</span>]</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>clean_df <span class="op">=</span> earthquake_df[columns_of_interest].copy()</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co">#drop rows with missing data</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>clean_df.dropna(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>clean_df.info()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 9787 entries, 0 to 9786
Data columns (total 4 columns):
 #   Column     Non-Null Count  Dtype  
---  ------     --------------  -----  
 0   mag        9787 non-null   float64
 1   depth      9787 non-null   float64
 2   latitude   9787 non-null   float64
 3   longitude  9787 non-null   float64
dtypes: float64(4)
memory usage: 306.0 KB
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="85"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="D_XH49sCY6z4" data-outputId="4817e9e7-a250-41ae-9153-42625ccd88de">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define features X and target Y</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> clean_df[[<span class="st">&#39;depth&#39;</span>, <span class="st">&#39;latitude&#39;</span>, <span class="st">&#39;longitude&#39;</span>]]</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> clean_df[<span class="st">&#39;mag&#39;</span>]</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># create training and testing variables</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, Y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co">#Baseline model</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> LinearRegression()</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>lr.fit(X_train, y_train)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>y_pred_lr <span class="op">=</span> lr.predict(X_test)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>r2_lr <span class="op">=</span> r2_score(y_test, y_pred_lr)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>mse_lr <span class="op">=</span> mean_squared_error(y_test, y_pred_lr)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Linear Regression -&gt; R² = </span><span class="sc">{</span>r2_lr<span class="sc">:.3f}</span><span class="ss">, MSE = </span><span class="sc">{</span>mse_lr<span class="sc">:.3f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Linear Regression -&gt; R² = 0.393, MSE = 0.930
</code></pre>
</div>
</div>
<div class="cell markdown" id="h47luUoO6Q1w">
<p>The R² value indicates that the relationship between the data is not
linear, so lets do a different approach that can handle complex
nonlinearities well such as a random forest regressor</p>
</div>
<div class="cell code" data-execution_count="86"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="6HaoYNHE409p" data-outputId="24debe01-4282-4296-a439-d74ca8814bb6">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># train random forest regressor</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestRegressor(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X_train, y_train)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict and evaluate</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>y_pred_rf <span class="op">=</span> rf_model.predict(X_test)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>r2_rf <span class="op">=</span> r2_score(y_test, y_pred_rf)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>mse_rf <span class="op">=</span> mean_squared_error(y_test, y_pred_rf)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Random Forest -&gt; R² = </span><span class="sc">{</span>r2_rf<span class="sc">:.3f}</span><span class="ss">, MSE = </span><span class="sc">{</span>mse_rf<span class="sc">:.3f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Random Forest -&gt; R² = 0.831, MSE = 0.259
</code></pre>
</div>
</div>
<section id="visualization" class="cell markdown" id="iz6YnYBFYSHT">
<h1>Visualization</h1>
<p>To evaluate how well our Random Forest Regressor model predicts
earthquake magnitude from geographic and geological features, we
visualize the relationship between the true magnitudes and the predicted
magnitudes on the test dataset.</p>
<p>We also display a graph representing the feature importances for the
model, giving transparency and insight on which features are relied on
during the prediction process.</p>
</section>
<div class="cell code" data-execution_count="87"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:997}"
id="eFKGP45sG11Q" data-outputId="e9485637-5e7c-4695-dcd8-290146ac1f1e">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature importances</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>importances <span class="op">=</span> rf_model.feature_importances_</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>feat_imp <span class="op">=</span> pd.Series(importances, index<span class="op">=</span>X.columns).sort_values(ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>feat_imp.plot(kind<span class="op">=</span><span class="st">&#39;barh&#39;</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Random Forest Feature Importances&quot;</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Importance&quot;</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted vs Actual scatter</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>plt.scatter(y_test, y_pred_rf, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>lims <span class="op">=</span> [Y.<span class="bu">min</span>(), Y.<span class="bu">max</span>()]</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>plt.plot(lims, lims, <span class="st">&#39;k--&#39;</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;True vs. Predicted Magnitude (RF)&quot;</span>)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;True Magnitude&quot;</span>)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Predicted Magnitude&quot;</span>)</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_f94581669a5f4ed79b9d0a92767380fb/a58d08c169b4d91b229488d91b150c4e21a6f79e.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_f94581669a5f4ed79b9d0a92767380fb/b2cfd6d12742c7943e64f2fb1d2f40cfdb429b8c.png" /></p>
</div>
</div>
<div class="cell markdown" id="CuTALqaHcHzl">
<p>As we can see, most of the points cluster closely around the ideal
fit line, indicating that the model generally performs well at
estimating earthquake magnitudes. However there is some visible
variance, suggesting that the nonlinear relationships were not captured
by the random forest regressor or other influential factors that aren't
seen in the data like tectonics.</p>
</div>
<section id="insights-and-conclusions" class="cell markdown"
id="fEqkuFBPYW6F">
<h1>Insights and Conclusions</h1>
</section>
<div class="cell markdown" id="W3psNw4ub0gX">
<p>This project set out to explore whether earthquake depth, latitude,
and longitude could be used to accurately predict earthquake magnitude
using a machine learning model, specifically, a Random Forest
Regressor.</p>
<p>For an uninformed reader, the analysis provides a clear and
accessible introduction to how geospatial features like where and how
deep an earthquake occurs may influence its strength. The
visualizations, such as the predicted vs. actual magnitudes plot, help
demonstrate the concept of model prediction in a way that is intuitive
and easy to interpret.</p>
<p>For a more informed reader such as someone who is familiar with
earthquakes/machine learning, the project goes further by demonstrating
the practical application of regression models on real-world data. It
quantifies model performance (R² ≈ 0.83, MSE ≈ 0.26) and discusses the
limitations of only using three features (depth, latitude, longitude),
highlighting opportunities for improvement such as including tectonic
plate data, fault lines, or temporal patterns that may have influenced
our results.</p>
</div>
</body>
</html>
